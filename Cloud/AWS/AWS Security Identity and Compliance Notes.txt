Security, Identity & Compliance
========================
IAM
	- Basics
		- Comprises of
			- Users
				- Users can be given 
					- Programmatic Access (API, CLI, SDK and other dev tools)
					- Console Access
				- User can be associated with 0 or more groups
				- You can copy permissions from a model user
				- you can attach existing policies directly (and override conflicting policies)
			- Groups 
				- Groups can be associated with 0 or more
					- AWS Managed Policies
					- Job Function 
						- SystemAdministrator, NetworkAdministrator, DatabaseAdministrator, ViewOnlyAccess
					- Custom Managed Roles
				- Groups can have 0 or more users

			- Roles 
				- Roles are associated with policies
			- Policies
	- IAM is universal - it does not apply to regions at this time
	- root account is simply the account created when you first setup AWS account - it has complete admin access
		- you should always setup MFA for this account
		- you can also customise password rotation policies
	- new users have no permissions when first created
	- New users are assigned Access Key id & Secret access keys  when first created
		- you can use this to access AWS via the APIs and command line
		- you only get to see this once, if you lose them you have to regenerate them
Security Groups
	- you can specify only allow rules - you can’t specify deny rules
	- Stateful - whatever inbound rules are created - it is automatically applied to outbound as well
	- you can’t block / blacklist a particular port
	- you can’t block individual IP address
	- changes to security groups take effect immediately
	- all inbound traffic is blocked by default - you need to add rules to enable them
	- you can assign multiple security groups to your EC2 instance
		- select EC2 instance
		- click on Actions -> Networking -> Change Security Groups and select multiple security groups
		- the result is the union of two sets of multiple groups
	- EC2 to Security Groups relationship is Many to Many
			
Cross Account Access
	- Within a multi-account (or multi-role) AWS environment, you can switch roles within Management Console
	- You can sign in to the console using your IAM username then switch the console to manage another account
		- without having to enter another user name and password

	- Steps
		- You need two AWS Accounts to test this
		- Say you have one account for production AWS account and one for developer AWS account
		- and you want to give S3 specific bucket access to your developers
		- First login in to developer AWS Account (as root)
			- create a group called “developer”
			- create a user (say shekhar)
		- Log in to production AWS account (as root)
			- In the IAM, 
				- create a policy called “read-write-app-bucket-policy” (see Bucket Policy section)
				- create a role called “MyDeveloperAccess”
					- select “Another AWS Account”
					- specify the developer AWS account id and leave rest as default
					- attach the newly created policy “read-write-app-bucket-policy” to it
		- Log back to developer AWS account (as root)
			- In the developer group that you created earlier
				- add an inline policy called “allow-assume-s3-role-in-production”
					- paste the inline policy (see Inline Policy section)
					- replace the production account id with the actual id of the other PROD AWS account id
		-  Log in to developer AWS account (as shekhar)
			- select the “Switch Role” menu option from your name drop down
				- specify the PROD AWS Account Id
				- specify the Role “MyDeveloperAccess”
				- specify the display name
		- You can now assume Developer access in Production Account
			- you can perform the operations in S3 bucket and see it works now


Bucket Policy - “read-write-app-bucket-policy”
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "s3:ListAllMyBuckets",
      "Resource": "arn:aws:s3:::*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket",
        "s3:GetBucketLocation"
       ],
      "Resource": "arn:aws:s3:::<your bucket name>“
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:GetObject",
        "s3:PutObject",
        "s3:DeleteObject"
      ],
      "Resource": "arn:aws:s3:::<your bucket name>/*"
    }
  ]
}

Inline policy - “allow-assume-s3-role-in-production”

{
  "Version": "2012-10-17",
  "Statement": {
    "Effect": "Allow",
    "Action": "sts:AssumeRole",
    "Resource": "arn:aws:iam::<PRODUCTION-ACCOUNT-ID>:role/MyDevelopersAccess"
  }
}

CloudHSM
- HSM stands for Hardware Security Module
- They are special devices which safeguards and manages digital keys for strong authentication
- These devices are "tamper resistant", that means if anyone tries to tamper they will automatically delete the keys stored
- HSM are typically certified against internationally recognised standard such as "Common Criteria" and "FIPS 140"
- Cloud HSM is Single Tenanted (Single Physical Device only for you)
- It must be used within a VPC
- Can be integrated with RedShift and RDS for Oracle
- For fault tolerance, we will need to build cluster of 2 Cloud HSM
- AWS uses "Safenet Luna SA HSM" appliance for Cloud HSM
- They are FIPS validated
- It generally has 2 partitions, one for AWS to monitor and second is cryptographic partition which you have access to and has stored keys
- Use case
	- typically used for compliance and for storing PII data keys
	- if the data is in cloud, it is recommended to use the CloudHSM than using on premise HSM to avoid latencies
- Disadvantages
	- they are expensive and to be fault tolerant requires at least a cluster of 2 physical devices
	- KMS is recommended to overcome the above



KMS (Key Management Service)
- AWS KMS is a managed Service which allows to create, manage and control the encryption keys and uses the HSMs to protect the security of the keys
- KMS supports only Symmetric Key Algorithm and uses AES-GCM with 256 bit keys
- Flow
	- Create a CMK - Specify an Alias
	- Define Administrative User and Key User
	- Key user can reference to the KMS key id and encrypt / decrypt data 
- Fully integrated with IAM for authorisation
- Anytime you need to share sensitive information ... use KMS
	- Database passwords
	- Credentials to external service
	- Private Key of SSL Certificates
- Seamlessly integrated into
	- Amazon EBS: encrypt volumes
	- Amazon S3: Server side encryption of objects
	- Amazon Redshift: Encryption of Data at rest
	- Amazon RDS: Encryption of Data
	- Amazon SSM: Parameter store
	- pretty much every service is integrated with KMS in some way
- CMK (Customer Master Key) is used to encrypt/decrypt data and AWS manages the CMK
	- you do not have any control on CMK
	- CMK also gets rotated by AWS
	- 3 types of CMK
		- AWS Managed Service Default CMK : Free
		- User Keys created in KMS : $1 / month
		- User Keys imported (must be 256-bit symmetric key) : $1 / month
		- Plus pay for API call to KMS : $0.03 / 10000 calls
- Encrypted secrets can be stored in the code / environment variables
- To give access to KMS to someone
	- Make sure the Key policy allows the user
	- Make sure the IAM policy allows API calls
- Able to fully manage the keys and policies
	- Create
	- Rotate Policies
	- Disable
	- Enable
- Able to audit key usage (using CloudTrail)
- See Encrypt and Decrypt Flow in the diagram (stored in the current directory)
- In place Encryption vs Migration
	- Following requires migration for encryption
		- EBS Volumes
		- RDS Databases
		- Elastic Cache
		- EFS network file system
		(unencrypted EBS Volume to be encrypted, you need to take a snapshot, encrypt the snapshot and restore EBS volume from snapshot - this is called migration, similar process for others)
	
	- In place encryption possible for the following
		- S3
- KMS only allows TLS connection (as we cannot send data in plaintext over the network)
- Caveats
	- KMS can only help in encrypting upto 4KB of data per call (Important)
		- if data > 4kb, you can use envelope encryption
		- AWS suggests CMK + Data key based approach (described in envelope encryption)
	- Since the data travels over the network, there is some latency involved
- Envelope Encryption
	- We generate 1 CMK
	- We then generate the Data key. AWS returns PT (Plaintext) & CT (CipherText) version of it
	- We use the plain text data key to encrypt the files in server
	- We then store Cipher text data key along with encrypted file
	- You can then delete the plain text data key and text file

- Envelope Decryption
	- Use the decrypt operation to decrypt the encrypted data key into a plaintext copy of the data key
	- Use the plain text data key to decrypt the stored encrypted file

- Architecture
	- Please see the KMS architecture diagram in the folder

- CMK and IAM Policy Evaluation logic
	- Both of the following should be yes
		- IAM Policy allows: Yes / No
		- CMK Policy allows: Yes / No

	If in CMK policy, root principal is used with allow kms:* and resource: * - it is considered as CMK level yes for all the users
	If in CMK policy, root principal is NOT used - it is considered as CMK level no unless explicit action given to specific user in CMK

	Also note that, if an explict deny specified at IAM policy but allowed at CMK policy level, the user will NOT be able to perform the operation
	
	In the under-mentioned case, user Alice will be able to perform both Encrypt and Decrypt as it is allowed in both IAM and at CMK level

	- IAM inline policy sample
    	{
            "Version": "2012-10-17",
            "Statement": [
                {
                    "Sid": "VisualEditor0",
                    "Effect": "Allow",
                    "Action": "kms:Encrypt",
                    "Resource": "arn:aws:kms:ap-northeast-1:871285060102:key/68e86af6-0db6-4fd1-8c17-fb8a20c766cd"
                }
            ]
        }

        CMK Key Policy sample
        {
            "Version": "2012-10-17",
            "Id": "key-consolepolicy-3",
            "Statement": [
                {
                    "Sid": "Enable IAM User Permissions",
                    "Effect": "Allow",
                    "Principal": {
                        "AWS": "arn:aws:iam::037742531108:root"
                    },
                    "Action": "kms:*",
                    "Resource": "*"
                },
                {
                    "Sid": "Allow access for Key Administrators",
                    "Effect": "Allow",
                    "Principal": {
                        "AWS": "arn:aws:iam::037742531108:user/Alice"
                    },
                    "Action": [
                        "kms:DescribeKey",
                        "kms:Decrypt*"
                    ],
                    "Resource": "*"
                }
            ]
        }

- KMS ViaService
	- You can specifically allow / deny specific services performing KMS operations under certain principal using KMS ViaService conditions
	- Example CMK policy below:

	- This will restrict user (principal) Alice from using any KMS operations that falls under EC2
	- for example creation of encrypted EBS volume 
		- try creating a encrypted EBS volume by selecting a KMS master key where the under-mentioned key policy is defined

	{
		"Id": "key-consolepolicy-3",
		"Version": "2012-10-17",
		"Statement": [{
				"Sid": "Enable IAM User Permissions",
				"Effect": "Allow",
				"Principal": {
					"AWS": "arn:aws:iam::888913816489:root"
				},
				"Action": "kms:*",
				"Resource": "*"
			},
			{
				"Sid": "Allow use of the key",
				"Effect": "Deny",
				"Principal": {
					"AWS": "arn:aws:iam::888913816489:user/Alice"
				},
				"Action": [
					"kms:Encrypt"
				],
				"Resource": "*",
	      "Condition": {
	        "ForAnyValue:StringEquals": {
	          "kms:ViaService": [
	            "ec2.us-east-1.amazonaws.com"
	         ]
	      }
	       }
			}
		]
	} 

	(you can also put "rds.us-east-1.amazonaws.com" or other service involving kms operation in that array to restrict further)

- KMS Grant
	- is similar to secret token that Granter grants to Grantee - token contains the permissions / operations that Grantee can perform on CMK
	- see CLI section for some of the commands


- CLI
	aws kms list-keys
	aws kms encrypt --key-id <key id> --plaintext "Some text" --query CiphertextBlob --output text | base64 -d > encrypteddemo.txt
	aws kms decrypt --ciphertext-blob file://encrypteddemo.txt --query Plaintext --output text | base64 -d

	'generate data keys (for envelope encryption) - returns plaintext and ciphertextblob
	aws kms generate-data-key --key-id <key id> --key-spec AES_256

	{
		"Plaintext" : "",
		"KeyId" : "<arn of the keyid>"
		"CiphertextBlob" : ""
	}

	(Granter performs this operation)
	aws kms create-grant --key-id <arn of the key id> --grantee-principal <grantee-user-arn> --operations "Encrypt" [--region <region-id> ]
	(you will get the GrantToken and GrantId as a json)

	aws kms revoke-grant --key-id <key id> --grant-id (grant-id) [--region <region-id>]

	(Grantee performs this operation and uses the grant-token)
	aws kms encrypt /
	--key-id <key id> /
	--plaintext "Some text" /
	--query CiphertextBlob /
	--output text /
	--grant-tokens <grant token received>
	| base64 -d > encrypteddemo.txt





SSM (Systems Manager) Parameter Store
- Secure storge for configuration and secrets
- Optional seamless encryption using KMS
- Serverless, scalable, durable, easy SDK, free
- Version tracking of configuration / secrets
- Configuration management using Path and IAM
- Notifications with Cloudwatch Events
- Integration with CloudFormation
- Sits on top of KMS
	- You can ask to retrieve plain text / encrypted configuration from SSM Parameter store
		- For Plain text configuration, checks for IAM permission and returns the configuration from store
		- For Encrypted configuration, 
			- First checks for IAM permission and then retrieves the encrypted configuration from store
			- Next it checks for KMS policies for decryption and then decrypts the encrypted configuration using KMS
	- Same applies for storing plain text / encrypted configuration

- Tree structured
	for ex:
		/ my-department/
			my-app/
				dev/
					db-url
					db-password
				prod/
					db-url
					db-password
			other-app/
		/ other-department/
	- you can then use GetParameter or GetParameterByPath API to get the respective department->app->env->db-url parameter from store

- Flow
	- Create a new parameter
	- Specify the parameter type and values
	- Reference parameters in your commands or code

	for eg: 
		parameter: /my-app/dev/db-url
		type: String / String List (comma separated) / SecureString
		value: dev.database.mydb.com:3306
		
		for secure string - specify additional info
		account: my account / another account
		kms key id: for eg: alias/tutorial or alias/aws/codecommit or alias/aws/rds or alias/aws/s3 or alias/aws/lambda
		value: (will not appear as you type)

		for retrieving from cli
		aws ssm get-parameters --names /my-app/dev/db-url /my-app/dev/db-password --with-decryption

		aws ssm get-parameters-by-path --path /my-app --recursive

	for the IAM role, you can simply add the following inline policies
		service: Systems Manager
		Actions: GetParameter and GetParameterByPath
		Resources: Specific or All Resources - select Specific
			Region: * (check Any checkbox)
			Account: * (check Any checkbox)
			Fully qualified parameter name: my-app/*

			this build the arn something like this: arn:aws:ssm:*:*:parameter/my-app/*

		service: KMS
		Actions: Under Access Level -> Write, select Decrypt
		Resources: Specific
			Region: *
			Account: *
			Key id: (get the key id from KMS screen - in this case, the key id for alias/tutorial)
			this build the arn something like this: arn:aws:kms:*:*:key/<keyid>/

	for Lambda function using python, following code should work
		import json
		import boto3
		import os

		ssm = boto3.client('ssm', region_name="ap-south-1")
		dev_or_prod = os.environ["DEV_OR_PROD"]

		def lambda_handler(event, context):
			dburl = ssm.get_parameters(Names=["/my-app/" + dev_or_prod + "/db-url"])
			dbpassword = ssm.get_parameters(Names=["/my-app/" + dev_or_prod + "/db-password"], WithDecryption=True)
			print(dburl)
			print(dbpassword)
			return "worked!"

Cognito 
	- provides authentication, authorization and user management service for your web and mobile apps
	- Web Identity Federation Service
	- Web identity federation is when you tried to sign in to a web site using an identity provider credentials (for eg google)
	- in other words Federation allows users to authenticate with a web identity provider
		- Federation means
			- combining or joining a list of users in one domain (such as IAM) with 
				- a list of users in another domain (such as Active Directory or Facebook)
			- Federation allows external identities (Federated Users) to have secure access in your AWS account
				- without having to create any IAM users

				- External Identities can come from corporate identity provider (AD, IPA) or web identity provider (facebook, amazon etc)
	- Identity broker
		- A service that allows you to take an identity from point A and join it (federate it) to point B
	- Web Identify Federation lets you give your users access to AWS resources once
		- they have successfully authenticated with a web-based identity provider (Amazon, Google, Facebook)
		- following successful authentication, the user receives an authenticate code that
			- they can then trade for temporary AWS security credentials
				- which maps to an IAM role allowing access to the required resources

	- Cognito is a web identity federation service - it has the following features
		- Sign up and sign in to your apps
		- Access for guest users
		- acts as an identity broker between your app and web identify provider, so no need to
			- write additional code
	⁃		- embed or store to AWS credentials locally on the device
			
		- synchronises user data for multiple devices
			- Cognito tracks the association between user identity and the various different devices they sign-in from
			- In order to seamless user experience for your application, 
				- Cognito uses push synchronisation to push updates and 
					- synchronises user data across multiple devices
					- Cognito uses SNS notification to all the devices associated with a given user identity
						- whenever data stored in the cloud changes
		- Recommended for all mobile applications AWS services

	- Cognito User Pools
		- User Pools are user directories used to manage sign-up and sign-in functionality for mobile and web apps
		- User can directly sign-in to the user pool 
			- username and password in Cognito
		or 
		- User can sign-in using Facebook/Amazon/Google
		- Cognito acts as an identity broker between identify provider and AWS
		- Successful authentication generates JSON Web Token (JWTs)
		- covers User registration, authentication and account recovery etc

		- User pools
			- Specify the name
			- Specify the attributes
				username with verified email address
				or username as email address or phone number
				other attributes that user can use during sign-up & sign-in process (family name, birthdate)
			- password strength
			- mfa (email and phone number) - aws will send sms on behalf your app
			- message customization
			- devices (remember user devices or not)

	- Cognito Identity Pools
		- Identity pool provides the functionality of federation of users in user pools
		- Identity pools enable provide temporary AWS credentials to access AWS services like S3 or DynamoDB
		- It is the one which actually authorises your access to your AWS resources
		- In other words, Cognito Identity pool take the identities from whichever source (custom, cognito user pool, social identity platforms and
			- provide secure access to the AWS services regardless of where the user comes from
		- (see diagram CognitoUserPoolvsIdentityPool)


	- Example scenario - user needs to access a website that allows Facebook credentials and uses cognate service
		- Flow would work like this
			- User accesses the website url - since user has not yet authenticated herself
			- she is routed to login screen with Facebook as one of the option
			- User chooses Facebook option and she is redirected to Facebook login page
			- user enters the username and password and Facebook authenticates the user
			- after successful authentication, Facebook generates and responds with an authentication code
			- the authentication code is then received by cognito user pool and it generates a JWT for the user
			- this JWT is then redirected to Cognito Identity pool on behalf of user 
			- Cognito identity pool then returns back AWS credentials in the form of an IAM role
			- user is then able to access the AWS resources that the IAM role supports

Security Token Service
	- Allows to create temporary credentials (token is valid for upto one hour - must be refreshed)
	- Cross Account Access (Allows users from one AWS account to access resources in another)
		- Flow
			- Define a IAM Role for another account to access
			- Define which accounts can access this IAM role
			- Use AWS STS to retrieve credentials and impersonate the IAM Role you have access to (AssumeRole API)
	- Federation (Active Directory)
		- Provides non-AWS user with temporary AWS access by linking users Active Directory credentials
		- Uses SAML (Security Assertion Markup Language)
		- Allows Single Sign-on (SSO) which enables users to log in to AWS console without assigning IAM credentials
	- Federation with third-party providers / Cognito
		- used mainly in web and mobile applications
		- Makes use of Facebook/Google/Azure to federate them

	use case
	- When developer working on his local environment and needs access to S3 in aws, 
		- he can be allowed to use sts to generate temporary credentials for accessing s3

	(follow the below to implement this use case)

	- Step 1: create a cross account role in IAM
		- while creating role, select the option "Another AWS Account" and specify the account id
		- in the permissions page, specify s3 and select s3readonly policy
		- specify a name for the role and create a role say ("STSRole")
	- Step 2: Attach a S3ReadOnly policy to that IAM Role
	- Step 3: Allow user to Assume Role with STS
		- For a selected user, click "Add inline policy" link in the user page
		- Choose a service - select STS
		- Actions - AssumeRole
		- Resources - add arn of the previous created role in step 1
	- Step 4: Remove all other policy from user except Assume Role
		- this step is only to ensure that no other action privilege is conflicting with our intended actions

	In the AWS Credentials file (available in file ~/.aws/credentials), add a section

	[myprofile]
	arn = <arn of the sts role>
	source-profile = default

	(default profile is the one that would be inferred when you run aws cli) 

	then you can run aws s3 commands with the profile 
	aws s3 ls --profile myprofile


	this command will then generate a temporary credential (access key, secret key, token) for the current user specified in default section

	internally it will execute the following command to generate temporary credential
	aws sts assume-role --role-arn <arn of the sts role created in step 1> --role-session-name "somesessionname"



	- Other Example scenarios
		- User needs to access a reporting application that enables access to user’s S3 bucket
		- User needs to be authenticated using organisation’s active directory
	- Flow works like this
		- Step 1: User logs into reporting application with username and password
		- Step 2: Identity Broker (for ex: Cognito) receives the username and password 
				and validates with Active Directory using LDAP protocol
		- Step 3: User is authenticated by Active Directory 
		- Step 4: Identity Broker contacts Security Token Service
			- Identity broker calls the new GetFederationToken function using IAM credentials.
			- The call must include an IAM policy and a duration (1 to 36 hours) 
			- Policy must specify the permissions to be granted to the temporary security credentials
		- Step 5: STS responds as per below
			- STS confirms that the policy of the IAM user making the call to GetFederationToken
			- Gives permission to create new tokens 
			- It returns four values to the application
				- Access Key ID
				- Access Secret Key
				- Token
				- Duration (Token’s lifetime)
		- Step 6: Cognito forwards the response to Application
		- Step 7: Application hits S3 with those STS response and requested action
		- Step 8: S3 contacts IAM to verify the token and whether the requested operation is permitted
		- Step 9: IAM confirms whether the token is valid and the requested operation is permitted and S3 responds
		
Macie
	- Powerful security and compliance enabling service 
		- under the Security, Identity and Compliance category in AWS  Management Console
	- Main function of Macie is to automatically detect, identify, classify and protect security data
	- Uses Machine Learning / AI for the above
	- Detection and Classification
		- Automatically and continuously monitors the new data stored in S3 
		- it learns from / analyses
			- the data access patterns
			- user behaviour
			- cloud trail event data
		- and it alerts from unusual and irregular activity 
			- It can automatically assign business values to data in the form of a risk score
				- allowing priorities of alerts to be established
		- It uses NLP methods to classify and interpret different data types and content
	- Protection of Data
		- Monitor and Discover security changes governing your data
		- identify security centric changes - such as access keys held in s3 bucket
			- identify critical, sensitive and security focused data - API keys, secret access keys, PII / PHI data
			- detect changes and alterations to security policies and access control lists
			- Maintain compliance requirements for various regulations

AWS Secret Manager
	- Enables customers to rotate, manage, retrieve db credentials, API keys and other credentials throughout their lifecycle
	- use versioning so applications do not break when secrets are rotated
	- Fine grained access control on who can access the secrets with the help of IAM and resource based policies

	Options
	- Credentials for RDS Database (Lambda function is created automatically for secret rotation and the logs are sent to cloudwatch logs)
	- Credentials for other database (Specify server address, database name, port number - Lambda function needs to be created manually for secret rotation)
	- Other type of secrets (for eg: API Key)

Certificate Manager


Web Application Firewall (WAF)
- AWS WAF is a web application firewall service that helps protect your web apps from common exploits that could affect app availability, compromise security, or consume excessive resources.
- AWS WAF is a web application firewall that lets you monitor the HTTP and HTTPS requests that are forwarded to an Amazon API Gateway API, Amazon CloudFront or an Application Load Balancer.
- AWS WAF also lets you control access to your content. Based on conditions that you specify, such as the IP addresses that requests originate from or the values of query strings, API Gateway, CloudFront or an Application Load Balancer responds to requests either with the requested content or with an HTTP 403 status code (Forbidden).

Six Conditions that it supports 
- SQL Injection attacks
- Cross-site scripting attacks
- Geographical locations that request originate from (Geo Match)
- Length of specified parts of the request  (Size constraints)
- IP addresses or address ranges that requests originate from
- Strings that appear within the requests

At the simplest level, AWS WAF lets you choose one of the following behaviors:
- Allow all requests except the ones that you specify
- Block all requests except the ones that you specify
- Count the requests that match the properties that you specify

Steps:
- Create one or more condition(s)
- Using the conditions create one or more rules (with new WAF, you can also create Rule Groups)
- Create Web ACL and apply the rules created earlier - if the rules match then you can choose one of the earlier stated behaviours
- Specify CloudFront / ALB / API Gateway in the web acl and the underlying aws resource of CloudFront / ALB / API Gateway
(You would need to precreate the resources (for eg: ALB) before creating web acl so that you can specify the reference of that resource in web acl)


AWS Shield
- Protects your workloads from Distributed Denial Of Service (DDoS) attacks
- Two types
	- Shield Standard (protection against the most common network and transport layer DDoS attacks)
	- Shield Advanced (near real time visibility into the attacks that might be occurring - gives customers 24 x 7 access to AWS DDoS response team (DRT)
		- During the attack, if the infrastructure has scaled, AWS will return the credits (only applicable for Route53, ELB, CloudFront)
		- Automated application (Layer 7) traffic monitoring
		- Expensive ($3000 per Organisation and additional cost)

- Mitigating DDoS attacks
	- Be ready to Scale
	- Minimise the attack surface area 
		- one server should run one service - for ex: application and database should not run on the same server
		- decouple your infrastructure - make use of services like SQS, ElasticBeanStalk
	- Know what is normal and what is abnormal
		- Key metrics need to be defined to understand the behaviour
			- Website reaching huge traffic in the middle of night
			- make use of services like Cloudwatch, SNS
	- Create a plan for attacks
		- Check whether the source IP address are same
		- Check from which country the increased traffic is coming from
		- Nature of attack (SYN flood, Application level)
		- Can it be blocked using NACL and Security Groups
		- It is recommended to have AWS support - at least the business support

	- Recommended Services that can be used to get protection from DDoS - Prevention Measures
		- Amazon CloudFront
		- Amazon Route53
		- Autoscaling Group
		- Elastic Load Balancing
		- AWS WAF
		- VPC, Security Groups, NACL

	- See this video for protection from attacks: https://www.youtube.com/watch?v=w9fSW6qMktA

	- Five DDoS Attack Vectors
		- UDP reflection attacks
		- UDP floods
		- TCP SYN floods
		- Web application layer attacks
		- DNS query floods
	- Four AWS use cases
		- Common web application
		- Highly resilient web application
		- Video game development
		- Voice communication

	DDoS attacks can
		- Target networks with large volumes of traffic
		- Target systems with large volumes of connections
		- Target services with large volumes of requests
		

Inspector
- CVE (Common Vulnerabilities & Exposure)
- CIS (Center for Internet Security) Benchmarks on OS Security 
- Security Best Practies
- Runtime behaviour and analysis


- Agent is installed on servers
- Scans and produces results
	- for CVEs, scans for vulnerabilities in all the packages
	- for OS, checks the server is following the hardening rules as per CIS benchmarks (not so mature product)
- Security Best Practices (supports the following 9 rules)
	- Disable root login via SSH
	- Support SSH V2 only
	- Disable Password Authentication via SSH
	- Configure maximum password age and minimum high
	- Configuring password complexity
	- Enable ASLR and DEP
	- Configure permissions for system directories	
- Runtime behaviour and Analysis
	- Insecure client protocols
	- Unused listening TCP ports
	- Insecure server protocols
	- Software without DEP
	- Software without Stack Cookies
	- Root process with insecure permission
Other tools that can be compared with Inspector
- Nessus
- Nexpose
- AWS Inspector
- OpenScap

Trusted Advisor
- Analyses your AWS environment provides best practice recommendations in 5 major categories:
	- Cost Optimisation
		- Idle / Under utilisation of
			- RDS DB Instance
			- EC2
			- Load Balancers
		- Unassociated Elastic IP Addresses
	- Performance
		- CloudFront Content Delivery Optimisation (s3 not using CloudFront)
	- Security
		- Security Groups - Unrestricted access
		- ELB Listener Security - not using recommended configurations for encrypted comm
		- S3 Bucket Permission
	- Fault Tolerance
		- RDS instance instance in Single AZ
		- EC2 Instances balancing across AZs
		- Age of snapshot of EBS
	- Service Limits
		- ASG Limit Checks when it reaches x% (say 80%) threshold
		- Similarly DynamicDB provisioned throughput reach limit
		- CloudFront stack limit

- Types of Checks
	- Core Checks
		- Security Group - Specific Port Unrestricted
		- IAM Use
		- MFA on Root Account
		- Performance: Service Limits

	- Access to All Trusted Advisor Checks ranging from
		- Security, Performance, Fault Tolerance & Cost Optimisation, Service Limits
	- Get weekly updates via email as well

 
Generating S3 Pre-signed url
aws s3 presign <uri>
aws s3 presign <bucketname>/<objectname>


SAML (Security Assertion Markup Langugage)
- It is an secure XML based communication mechanism for communicating identities across organisations
- It eliminates the need to maintain multiple authentication credentials such as passwords in multiple locations


- Flow works like this
	- user opens the idp (identity provider's) url and enters Username and password
	- IdP will validate the credential and associated permisson and then user receives SAML assertion from the IdP as part of the response
	- User does a POST of that SAML assertion to the SAAS sign in page and SP will validate those assertion
	- On validation, SP will construct relevant temporary credentials and construct URL for the console and sends to the user

https://signin.aws.amazon.com/static/saml-metadata.xml
https://sso.jumpcloud.com/saml2/aws

arn:aws:iam::434265470577:role/SSOFromJumpCloud

arn:aws:iam::434265470577:role/SSOFromJumpCloud,arn:aws:iam::434265470577:saml-provider/JumpCloud

AWS Directory Service
- It is a managed service based on cloud that allows us to create directories
	- takes care of high availability, monitoring, backup, recovery, patching etc.
	- The server running the Active Directory service is called the Domain Controller
		- it can authenticate and authorize the users and computers associated to it
- There are three components
	- Active Directory Service with Microsoft Active Directory (Windows Server with AD installed) - AWS Managed
	- Simple AD (Samba 4 compatible server) - Samba as Microsoft Active Directory Domain Controller
		- Microsoft AD compatible directory from AWS Directory Service that is powered by Samba 4
		- Supports AD features such as user accounts, group memberships, joining a Linux Domain, Kerberos based SSO and group policies
		- AWS provides monitoring, daily snapshots and recovery as part of the service
		- Does NOT support trust relationships, MFA, DNS dynamic update, schema extensions, communication over LDAPS, Powershell AD
	- AD Connector - It is a proxy service that provides a easy way to connect applications in cloud to your existing on premise Microsoft AD
		- When user logs in to the applications, AD Connector forwards the sign-in requests to your on-premise AD Domain Controllers for authentication
		- You need to setup VPN Tunnel for the same


- to let ec2 instances join the domain
	- create simple ad directory service (name it simplead.xyz.com) - note down the simplead administrator password
	- once created, note down the dns addresses (you will see 2 ip addresses)
	- create a ec2 instance
	- ssh into it
	- install sssd, realmd, krb5-workstation (yum -y install sssd, realmd, krb5-workstation)
	- in the /etc/resolv.conf (setup the nameservers using the earlier noted ip addresses) - add the following lines and save
		nameserver <first ip address>
		nameserver <second ip address>
	- now if you do - nslookup simplead.xyz.com - you should be able to resolve it with the above mentioned addresses
	- realm join -U administrator@simplead.xyz.com simplead.xyz.com --verbose (provide the simplead administrator password)
		- you should see the message "successfully enrolled machine in realm"
	- vi /etc/ssh/sshd_config
		- change the line "Enable PasswordAuthentication yes"
	- nano /etc/sudoers
		- add the following line
		- %Domain\ Admins@example.com ALL=(ALL:ALL) ALL

	- service sssd restart
	- service sshd restart
	
Trust Relationships
- In AWS, we can create "Trust Relationships" for IAM Role so that we can have cross-account IAM Access.

AWS Cross account trust example policy
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::434265470577:root"
      },
      "Action": "sts:AssumeRole",
      "Condition": {}
    }
  ]
}

two accounts are involved: Source Account where the role is assumed, other account where cross account role is created

AD Trusts
- In AD, domain to domain communication can occur through Trusts

- An AD DS trust is a secured, authentication communication channel between entities, such as AD DS domains

- Trusts enable you to grant access to resources to users, groups and computers across entities

- Sample trust between
domain1.xyz.com	-> domain2.xyz.com

Direction of Trust
	- Trust can either be one way or two ways
	- In two way trust, domain from either side can access the other side

- You can use AD for accessing AWS management console and aws apps & services (RDS)
- You can access Amazon EC2 instances using AD
- Further You can use AD aware workloads (SQL Server, Sharepoint, .NET Applications, RDP Licensing Manager)
- You can setup AWS Microsoft AD Directory to enable the above
- Alternatively, you can establish trust between AWS Microsoft AD Directory and On Premise Microsoft AD
	- Thus on premise users can access any of the above mentioned services
- Further you can setup 
	- AD FS  for federating users with other SaaS or external service providers (say Office 365)
	- ADSync for synchronising users to Azure AD




